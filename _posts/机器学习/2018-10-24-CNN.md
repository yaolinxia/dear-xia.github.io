---
layout: post
title: "CNN"
tag: 机器学习
---

## 特点：

- 卷积层与全连接层的区别，是可以保全空间结构
- 此处卷积其实和点积没有区别
- 黑白图片：还只有一个颜色通道；彩色图片：有三个颜色通道
- 传统神经网络：全连接层；CNN：局部连接，权值共享

![](https://ws1.sinaimg.cn/large/e93305edgy1fwj30oimk3j212t0lknbe.jpg)



## 卷积如何遍历：

- 会使用一组卷积核

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj3ho64q1j213m0mg17d.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj3j4j7r3j20x80k64a1.jpg)

  ~~~
  32-5+1=28
  ~~~

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj3kp42zgj211d0kitjd.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj3xoctaxj21450my4qp.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj3zpz7w0j212j0le1kx.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj42kxzmaj20u40m0wmc.jpg)

  ~~~
  步长为1
  ~~~

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj43l4lgij20z70irjwr.jpg)

  ~~~
  步长为2
  ~~~

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj447g5rhj20yw0i6k1w.jpg)

  ~~~
  步长为3，不能很好地拟合
  ~~~

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj456e4goj21240in0zj.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj4bjka4dj21160latk1.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj4koyd3vj212y0jrqe3.jpg)

  ![](https://ws1.sinaimg.cn/large/e93305edgy1fwj56jzld0j20z00iy7jq.jpg)

## 局部连接与权值共享：

下图是一个很经典的图示，左边是全连接，右边是局部连接。

  [![img](http://i.imgur.com/PHbta3D.jpg)](http://i.imgur.com/PHbta3D.jpg)

- 对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此数目巨大的参数几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。

- **进一步减少数量级：权值共享**。在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，**将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同**，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 **10 × 10个权值参数**（也就是卷积核(也称滤波器)的大小），如下图。

  [![img](http://i.imgur.com/IIBM59H.jpg)](http://i.imgur.com/IIBM59H.jpg)

- 这大概就是CNN的一个神奇之处，尽管只有这么少的参数，依旧有出色的性能。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加**多个卷积核**，不同的卷积核能够得到图像的不同映射下的特征，称之为**Feature Map**。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。另外，偏置参数也是共享的，同一种滤波器（卷积核）共享一个。

- **核心思想：**局部感受野

## 网络结构：

### LetNet-5结构：

![img](http://i.imgur.com/qMs50Ma.png)

- CNN中主要有两种类型的网络层，分别是**卷积层**和**池化/采样层(Pooling)**。卷积层的作用是提取图像的各种特征；池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。

## 卷积层：

- 卷积层是**卷积核**在上一级输入层上通过逐一滑动窗口计算而得，卷积核中的每一个参数都相当于传统神经网络中的权值参数，与对应的局部像素相连接，将卷积核的各个参数与对应的局部像素值相乘之和，（通常还要再加上一个偏置参数），得到卷积层上的结果。如下图所示。

[![img](http://i.imgur.com/w8enPv2.png)](http://i.imgur.com/w8enPv2.png)

下面的动图能够更好地解释卷积过程：

[![img](http://i.imgur.com/KPyqPOB.gif)](http://i.imgur.com/KPyqPOB.gif)

## 池化/采样层：

- 通过卷积层获得了图像的特征之后，理论上我们可以直接使用这些特征训练分类器（如**softmax**），但是这样做将面临巨大的计算量的挑战，而且容易产生过拟合的现象。为了进一步降低网络训练参数及模型的过拟合程度，我们对卷积层进行**池化/采样(Pooling)**处理。池化/采样的方式通常有以下两种：

- **Max-Pooling**: 选择Pooling窗口中的最大值作为采样值；
- **Mean-Pooling**: 将Pooling窗口中的所有值相加取平均，以平均值作为采样值；

如下图所示。

[![img](http://i.imgur.com/bHBUsr4.png)](http://i.imgur.com/bHBUsr4.png)

### LeNet-5网络详解：

以上较详细地介绍了CNN的网络结构和基本原理，下面介绍一个经典的CNN模型：**LeNet-5网络**。

[![img](http://i.imgur.com/2AuotA0.png)](http://i.imgur.com/2AuotA0.png)

[![img](http://i.imgur.com/Zzm048o.png)](http://i.imgur.com/Zzm048o.png)

[![img](http://i.imgur.com/aJlgVHg.png)](http://i.imgur.com/aJlgVHg.png)

[](http://i.imgur.com/SiVPyWR.png)



[![img](http://i.imgur.com/gTphBu6.png)](http://i.imgur.com/gTphBu6.png)

[![img](http://i.imgur.com/6L3CmUc.png)](http://i.imgur.com/6L3CmUc.png)

[![img](http://i.imgur.com/SNLgNWe.png)](http://i.imgur.com/SNLgNWe.png)

[![img](http://i.imgur.com/kJtbaEz.png)](http://i.imgur.com/kJtbaEz.png)

**LeNet-5网络在MNIST数据集上的结果**

[![img](http://i.imgur.com/cXSxkVY.png)](http://i.imgur.com/cXSxkVY.png)

## CNN层级结构：

### 数据输入层/ Input layer：

- 去均值：把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。
- 归一化：幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。
- PCA/白化：用PCA降维；白化是对数据各个特征轴上的幅度归一化

去均值与归一化效果图：

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194338194-1949897491.jpg)

 

去相关与白化效果图：

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194357553-1200745791.jpg)

### 卷积计算层/ CONV layer：

#### 两个关键操作

1. 局部关联，把每个神经元看做一个滤波器（filter）
2. 窗口（receptive field）滑动，filter对局部数据计算

#### 相关名词：

1. 深度（depth）
2. 步长（stride）
3. 填充值（zero-padding）

#### 局部关联：



![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194425147-845167791.png)

  填充值是什么呢？以下图为例子，比如有这么一个5*5的图片（一个格子一个像素），我们滑动窗口取2*2，步长取2，那么我们发现还剩下1个像素没法滑完，那怎么办呢？

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194452615-1175169258.png)

那我们在原先的矩阵加了一层填充值，使得变成6*6的矩阵，那么窗口就可以刚好把所有像素遍历完。这就是填充值的作用。

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194526537-1629104898.png)

卷积计算：
![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194547100-2091436500.jpg)
这里的蓝色矩阵就是输入的图像，粉色矩阵就是卷积层的神经元，这里表示了有两个神经元（w0,w1）。绿色矩阵就是经过卷积运算后的输出矩阵，这里的步长设置为2。

 ![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194612319-1829801420.jpg)

蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加（比如上面图的计算：2+（-2+1-2）+（1-2-2） + 1= 2 - 3 - 3 + 1 = -3），计算后的值就是绿框矩阵的一个元素。

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194806256-1671846037.png)

 

下面的动态图形象地展示了卷积层的计算过程：

 ![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194655881-1051795560.gif)



### ReLU激励层 / ReLU layer：

把卷积层输出结果做非线性映射。
![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194934006-705271151.jpg)
CNN采用的激励函数一般为ReLU(The Rectified Linear Unit/修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下。

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430194958725-2144325242.png)

 **一些注意事项：**
　　①不要用sigmoid！不要用sigmoid！不要用sigmoid！
　　② 首先试RELU，因为快，但要小心点
　　③ 如果2失效，请用Leaky ReLU或者Maxout
　　④ 某些情况下tanh倒是有不错的结果，但是很少



### 池化层 / Pooling layer：

压缩数据和参数的量， 其关键是减少过拟合。

如果是针对图像，那么气最重要的就是压缩图片 

#### 具体作用：

- 特征不变性
- 特征降维
- 防止过拟合

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430195028600-318072954.jpg)
池化层用的方法有Max pooling 和 average pooling，而实际用的较多的是Max pooling。

这里就说一下Max pooling，其实思想非常简单。
![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430195106397-414671399.jpg)
对于每个2*2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2*2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。



### 全连接层 / FC layer：

一般在神经网络尾部。

![img](https://images2015.cnblogs.com/blog/1093303/201704/1093303-20170430195130772-454262568.jpg)

**一般CNN结构依次为**

　　1.	INPUT
　　2.	[[CONV -> RELU]*N -> POOL?]*M 
　　3.	[FC -> RELU]*K
　　4.	FC

**卷积神经网络之训练算法**

  　　1.	同一般机器学习算法，先定义Loss function，衡量和实际结果之间差距。
    　　2.	找到最小化损失函数的W和b， CNN中用的算法是SGD（随机梯度下降）。

**卷积神经网络之优缺点**
优点
　　•	共享卷积核，对高维数据处理无压力
　　•	无需手动选取特征，训练好权重，即得特征分类效果好
缺点
　　•	需要调参，需要大样本量，训练最好要GPU
　　•	物理含义不明确（也就说，我们并不知道没个卷积层到底提取到的是什么特征，而且神经网络本身就是一种难以解释的“黑箱模型”）

**卷积神经网络之典型CNN**
　　•	LeNet，这是最早用于数字识别的CNN
　　•	AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比
　　•	LeNet更深，用多层小卷积层叠加替换单大卷积层。
　　•	ZF Net， 2013 ILSVRC比赛冠军
　　•	GoogLeNet， 2014 ILSVRC比赛冠军
　　•	VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好


**卷积神经网络之 fine-tuning**
何谓fine-tuning？
fine-tuning就是使用已用于其他目标、预训练好模型的权重或者部分权重，作为初始值开始训练。

那为什么我们不用随机选取选几个数作为权重初始值？原因很简单，第一，自己从头训练卷积神经网络容易出现问题；第二，fine-tuning能很快收敛到一个较理想的状态，省时又省心。

那fine-tuning的具体做法是？
　　•	复用相同层的权重，新定义层取随机权重初始值
　　•	调大新定义层的的学习率，调小复用层学习率


**卷积神经网络的常用框架**

**Caffe**
　　•	源于Berkeley的主流CV工具包，支持C++,python,matlab
　　•	Model Zoo中有大量预训练好的模型供使用
**Torch**
　　•	Facebook用的卷积神经网络工具包
　　•	通过时域卷积的本地接口，使用非常直观
　　•	定义新网络层简单
**TensorFlow**
　　•	Google的深度学习框架
　　•	TensorBoard可视化很方便
　　•	数据和模型并行化好，速度快

 **卷积神经网络之典型CNN**
　　•	LeNet，这是最早用于数字识别的CNN
　　•	AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比
　　•	LeNet更深，用多层小卷积层叠加替换单大卷积层。
　　•	ZF Net， 2013 ILSVRC比赛冠军
　　•	GoogLeNet， 2014 ILSVRC比赛冠军
　　•	VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好


**卷积神经网络之 fine-tuning**
何谓fine-tuning？
fine-tuning就是使用已用于其他目标、预训练好模型的权重或者部分权重，作为初始值开始训练。

那为什么我们不用随机选取选几个数作为权重初始值？原因很简单，第一，自己从头训练卷积神经网络容易出现问题；第二，fine-tuning能很快收敛到一个较理想的状态，省时又省心。

那fine-tuning的具体做法是？
　　•	复用相同层的权重，新定义层取随机权重初始值
　　•	调大新定义层的的学习率，调小复用层学习率


**卷积神经网络的常用框架**

**Caffe**
　　•	源于Berkeley的主流CV工具包，支持C++,python,matlab
　　•	Model Zoo中有大量预训练好的模型供使用
**Torch**
　　•	Facebook用的卷积神经网络工具包
　　•	通过时域卷积的本地接口，使用非常直观
　　•	定义新网络层简单
**TensorFlow**
　　•	Google的深度学习框架
　　•	TensorBoard可视化很方便
　　•	数据和模型并行化好，速度快

 

### 参考网址：

- <http://www.jeyzhang.com/cnn-learning-notes-1.html>
- <http://www.cnblogs.com/skyfsm/p/6790245.html>（强烈推荐）