---
layout: post
title: "Linguistically-Informed Self-Attention for Semantic Role Labeling"
tag: 文献阅读
---

- [Emma Strubell](https://dblp.uni-trier.de/pers/hd/s/Strubell:Emma), [Patrick Verga](https://dblp.uni-trier.de/pers/hd/v/Verga:Patrick), [Daniel Andor](https://dblp.uni-trier.de/pers/hd/a/Andor:Daniel), [David Weiss](https://dblp.uni-trier.de/pers/hd/w/Weiss:David), [Andrew McCallum](https://dblp.uni-trier.de/pers/hd/m/McCallum:Andrew):
  **Linguistically-Informed Self-Attention for Semantic Role Labeling.** [EMNLP 2018](https://dblp.uni-trier.de/db/conf/emnlp/emnlp2018.html#StrubellVAWM18): 5027-5038
- 语义角色标注中语言知情的自我关注

# **摘要**

- 提出了将 multi-head self-attention 与多任务学习相结合的模型，该模型可以仅使用原始的 token 对序列进行一次编码，来同时执行多个预测任务。